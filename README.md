
# ğŸ§  MOR-GPT

**MOR-GPT** is a from-scratch implementation of a transformer-based **Large Language Model (LLM)** designed for domain-specific conversational intelligence.  
It integrates a complete MLOps pipeline for training, versioning, deployment, and monitoring â€” bridging cutting-edge research and production engineering.

---

## ğŸ“œ Abstract

MOR-GPT explores how small, domain-adapted LLMs can be constructed from first principles without relying on pre-trained checkpoints.  
The model was built to understand and respond to technical queries related to AI, ML, and MLOps, and serves as a foundation for future scalable LLM architectures.

---

## ğŸ¯ Objectives

- Build a complete LLM stack from scratch: tokenizer â†’ transformer â†’ trainer â†’ inference.
- Deploy the model in a production-grade MLOps pipeline.
- Enable real-time chat-based interaction through a web interface.
- Provide full experiment reproducibility and version control.

---

## ğŸ§© System Architecture

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Raw Corpus  â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Custom Tokenizerâ”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Transformer Architecture â”‚
    â”‚ (Encoder-Decoder)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Training Engine â”‚
        â”‚ (PyTorch)        â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ FastAPI Inference API  â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ React Frontend â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

## âš™ï¸ Core Components

### ğŸ“ Tokenizer
- Built from a domain-specific dataset (AI/ML/MLOps concepts, personal Q&A)
- Byte Pair Encoding (BPE)-like tokenization
- `<pad>, <unk>, <bos>, <eos>` special tokens
- Vocabulary size: 3000

### ğŸ§  Model Architecture
- Transformer-based (Encoder-Decoder)
- Multi-head self-attention
- Feed-forward layers with residual connections and layer norm
- Positional encodings and attention masking
- Teacher forcing during training

### ğŸ“Š Training Pipeline
- Data preprocessing and batching
- Cross-entropy loss with gradient clipping
- Checkpointing and resume support
- Metrics tracked via **MLflow**

### ğŸ–¥ï¸ Deployment & MLOps
- Inference served via **FastAPI**
- Containerized with **Docker**
- CI/CD automation using **GitHub Actions**
- Experiment tracking and model registry using **MLflow**

### ğŸ’¬ Frontend Interface
- Built with **React** + **TypeScript**
- Real-time chat interface
- Model selection and progress indicators
- Displays training metrics and response logs

---

## ğŸ“ Repository Structure


---

## âš¡ Tech Stack

| Layer        | Technology           |
|--------------|--------------------------|
| Model        | PyTorch                  |
| API Backend  | FastAPI                  |
| Frontend     | React + TypeScript       |
| MLOps         | MLflow, Docker, GitHub Actions |
| Language     | Python, TypeScript       |

---

## ğŸ“ˆ Current Status

- âœ… Tokenizer implemented  
- âœ… Transformer architecture implemented  
- âœ… Data pipeline complete  
- âœ… Backend and Frontend fully integrated  
- âš¡ Training run in progress  
- ğŸ“Œ Evaluation benchmarks coming soon  

---

## ğŸ“Š Example Outputs *(Coming Soon)*

- Training loss and accuracy plots
- Sample inference responses
- MLflow experiment dashboard screenshots
- Tokenization samples

---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/RayAKaan/MOR-GPT_Model.git
cd MOR-GPT_Model

### Backend setup
cd app
uvicorn main:app --reload

### Frontend setup
cd frontend
npm install
npm run dev
